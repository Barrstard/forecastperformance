import { BigQuery } from '@google-cloud/bigquery'
import { prisma } from './prisma'

export interface BigQueryCredentials {
  type: string
  project_id: string
  private_key_id: string
  private_key: string
  client_email: string
  client_id: string
  auth_uri: string
  token_uri: string
  auth_provider_x509_cert_url: string
  client_x509_cert_url: string
}

export interface ConnectionResult {
  success: boolean
  projectId: string
  error?: string
}

export interface SyncResult {
  projectId: string
  dataset: string
  volumeForecastCount: number
  actualVolumeCount: number
  businessStructureCount: number
  calendarDayCount: number
  fiscalCalendarDayCount: number
}

export class BigQueryService {
  private client: BigQuery | null = null
  private projectId: string = ''
  private dataset: string = 'superretailgroup_detail' // Default dataset name, but configurable

  async connectWithCredentials(jsonCredentials: string | object, dataset?: string): Promise<string> {
    // Parse credentials and extract project ID
    const credentials = typeof jsonCredentials === 'string' 
      ? JSON.parse(jsonCredentials) 
      : jsonCredentials as BigQueryCredentials
    
    this.projectId = credentials.project_id
    
    if (!this.projectId) {
      throw new Error('Project ID not found in credentials')
    }
    
    // Set dataset if provided, otherwise keep default
    if (dataset) {
      this.dataset = dataset
    }
    
    this.client = new BigQuery({
      projectId: this.projectId,
      credentials: credentials
    })
    
    return this.projectId
  }

  async testConnection(): Promise<ConnectionResult> {
    if (!this.client || !this.projectId) {
      return { 
        success: false, 
        projectId: this.projectId,
        error: 'BigQuery client not initialized. Call connectWithCredentials first.' 
      }
    }

    try {
      // First, test basic connection by listing datasets
      const [datasets] = await this.client.getDatasets()
      const datasetNames = datasets.map(dataset => dataset.id)
      
      // Check if our required dataset exists
      if (!datasetNames.includes(this.dataset)) {
        return { 
          success: false, 
          projectId: this.projectId,
          error: `Dataset '${this.dataset}' not found in project '${this.projectId}'. Available datasets: ${datasetNames.join(', ')}` 
        }
      }
      
      // Test connection by querying dataset metadata
      const query = `
        SELECT table_name 
        FROM \`${this.projectId}.${this.dataset}.INFORMATION_SCHEMA.TABLES\` 
        LIMIT 1
      `
      await this.client.query({ query })
      
      return { success: true, projectId: this.projectId }
    } catch (error: any) {
      // Provide more specific error messages
      if (error.message.includes('Not found: Dataset')) {
        return { 
          success: false, 
          projectId: this.projectId,
          error: `Dataset '${this.dataset}' not found in project '${this.projectId}'. Please ensure the dataset exists and your service account has access to it.` 
        }
      }
      
      return { 
        success: false, 
        projectId: this.projectId,
        error: error.message 
      }
    }
  }

  async extractVolumeForecasts(
    startDate: string, 
    endDate: string,
    orgIds?: number[]
  ) {
    if (!this.client) {
      throw new Error('BigQuery client not initialized')
    }

    const orgFilter = orgIds?.length 
      ? `AND orgId IN (${orgIds.join(',')})` 
      : ''
      
    const query = `
      SELECT 
        orgId,
        partitionDate,
        volumeType,
        volumeTypeId,
        currency,
        currencyId,
        eventRatio,
        dailyAmount,
        volumeDriver,
        volumeDriverId,
        updateDtm,
        linkedCategoryType,
        includeSummarySwt
      FROM \`${this.projectId}.${this.dataset}.vVolumeForecast\`
      WHERE partitionDate BETWEEN '${startDate}' AND '${endDate}'
      ${orgFilter}
      ORDER BY partitionDate, orgId
    `
    
    const [rows] = await this.client.query({ query })
    return rows
  }

  async extractActualVolumes(
    startDate: string, 
    endDate: string,
    orgIds?: number[]
  ) {
    if (!this.client) {
      throw new Error('BigQuery client not initialized')
    }

    const orgFilter = orgIds?.length 
      ? `AND orgId IN (${orgIds.join(',')})` 
      : ''
      
    const query = `
      SELECT 
        orgId,
        partitionDate,
        dailyAmount,
        volumeDriverId,
        posLabel,
        posLabelId,
        updateDtm,
        linkedCategoryType,
        includeSummarySwt
      FROM \`${this.projectId}.${this.dataset}.vActualVolume\`
      WHERE partitionDate BETWEEN '${startDate}' AND '${endDate}'
      ${orgFilter}
      ORDER BY partitionDate, orgId
    `
    
    const [rows] = await this.client.query({ query })
    return rows
  }

  async extractBusinessStructure(orgIds?: number[]) {
    if (!this.client) {
      throw new Error('BigQuery client not initialized')
    }

    const orgFilter = orgIds?.length 
      ? `WHERE orgId IN (${orgIds.join(',')})` 
      : ''
      
    const query = `
      SELECT 
        orgId,
        parentOrgId,
        parentOrgName,
        name,
        fullName,
        description,
        effectiveDate,
        expirationDate,
        firstRevision,
        lastRevision,
        transferable,
        orgTypeId,
        orgTypeName,
        orgPathTxt,
        contextName,
        locationCategory,
        orgLevel,
        -- All orgBreak fields 1-25 with descriptions
        orgBreak1, orgBreak1Desc,
        orgBreak2, orgBreak2Desc,
        orgBreak3, orgBreak3Desc,
        orgBreak4, orgBreak4Desc,
        orgBreak5, orgBreak5Desc,
        orgBreak6, orgBreak6Desc,
        orgBreak7, orgBreak7Desc,
        orgBreak8, orgBreak8Desc,
        orgBreak9, orgBreak9Desc,
        orgBreak10, orgBreak10Desc,
        orgBreak11, orgBreak11Desc,
        orgBreak12, orgBreak12Desc,
        orgBreak13, orgBreak13Desc,
        orgBreak14, orgBreak14Desc,
        orgBreak15, orgBreak15Desc,
        orgBreak16, orgBreak16Desc,
        orgBreak17, orgBreak17Desc,
        orgBreak18, orgBreak18Desc,
        orgBreak19, orgBreak19Desc,
        orgBreak20, orgBreak20Desc,
        orgBreak21, orgBreak21Desc,
        orgBreak22, orgBreak22Desc,
        orgBreak23, orgBreak23Desc,
        orgBreak24, orgBreak24Desc,
        orgBreak25, orgBreak25Desc,
        updateDtm,
        genericJobId,
        genericJobName,
        jobId,
        timezoneBreakName,
        currencyId,
        currencyBreakName,
        costCenterId,
        persistentId,
        indirectWorkPercent,
        color,
        externalId,
        indirectWorkLimit,
        genericLocationId,
        genericLocationName,
        costCenterBreakName
      FROM \`${this.projectId}.${this.dataset}.vBusinessStructure\`
      ${orgFilter}
    `
    
    const [rows] = await this.client.query({ query })
    return rows
  }

  async extractCalendarData(startDate: string, endDate: string) {
    if (!this.client) {
      throw new Error('BigQuery client not initialized')
    }

    const query = `
      SELECT 
        date,
        dayName,
        dayOfWkNbr,
        lastDayOfQtrSwt,
        dayOfYrNbr,
        wkOfYrNbr,
        dayOfMoNbr,
        wkendSwt,
        moOfYrNbr,
        moName,
        qtrOfYrNbr,
        dayOfQtrNbr,
        yrNbr,
        qtrName,
        yrMoNbr,
        lastDayOfWkSwt,
        lastDayOfMoSwt
      FROM \`${this.projectId}.${this.dataset}.vCalendarDate\`
      WHERE date BETWEEN '${startDate}' AND '${endDate}'
      ORDER BY date
    `
    
    const [rows] = await this.client.query({ query })
    return rows
  }

  async extractFiscalCalendarData(startDate: string, endDate: string) {
    if (!this.client) {
      throw new Error('BigQuery client not initialized')
    }

    const query = `
      SELECT 
        date,
        fsclDayOfYear,
        fsclWeekOfYear,
        fsclMonthOfYearNbr,
        fsclMonthOfYearName,
        fsclQtrOfYearNbr,
        fsclQtrOfYearName,
        fsclYear,
        monthHours,
        updateDtm
      FROM \`${this.projectId}.${this.dataset}.vFiscalCalendar\`
      WHERE date BETWEEN '${startDate}' AND '${endDate}'
      ORDER BY date
    `
    
    const [rows] = await this.client.query({ query })
    return rows
  }

  async getAvailableTables(): Promise<string[]> {
    if (!this.client) {
      throw new Error('BigQuery client not initialized')
    }

    // Query available tables in the dataset
    const query = `
      SELECT table_name
      FROM \`${this.projectId}.${this.dataset}.INFORMATION_SCHEMA.TABLES\`
      WHERE table_type = 'BASE_TABLE'
      ORDER BY table_name
    `
    
    const [rows] = await this.client.query({ query })
    return rows.map((row: any) => row.table_name)
  }

  // Batch sync method for complete data extraction
  async syncCompleteDataset(
    runId: string,
    startDate: string,
    endDate: string,
    orgIds?: number[]
  ): Promise<SyncResult> {
    if (!this.projectId) {
      throw new Error('BigQuery client not initialized. Call connectWithCredentials first.')
    }
    
    // Extract all data in parallel from the fixed dataset
    const [
      volumeForecasts,
      actualVolumes, 
      businessStructure,
      calendarData,
      fiscalCalendarData
    ] = await Promise.all([
      this.extractVolumeForecasts(startDate, endDate, orgIds),
      this.extractActualVolumes(startDate, endDate, orgIds),
      this.extractBusinessStructure(orgIds),
      this.extractCalendarData(startDate, endDate),
      this.extractFiscalCalendarData(startDate, endDate)
    ])
    
    // Transform and batch insert into PostgreSQL
    await this.batchInsertToPostgreSQL(runId, {
      volumeForecasts,
      actualVolumes,
      businessStructure,
      calendarData,
      fiscalCalendarData
    })
    
    return {
      projectId: this.projectId,
      dataset: this.dataset,
      volumeForecastCount: volumeForecasts.length,
      actualVolumeCount: actualVolumes.length,
      businessStructureCount: businessStructure.length,
      calendarDayCount: calendarData.length,
      fiscalCalendarDayCount: fiscalCalendarData.length
    }
  }

  private async batchInsertToPostgreSQL(runId: string, data: any) {
    // Use Prisma batch operations for efficient insertion
    // Transform BigQuery data to PostgreSQL format and insert
    
    // Example batch insert for volume forecasts
    const volumeForecastData = data.volumeForecasts.map((row: any) => ({
      runId,
      orgId: row.orgId,
      partitionDate: new Date(row.partitionDate.value),
      volumeType: row.volumeType,
      volumeTypeId: row.volumeTypeId,
      currency: row.currency,
      currencyId: row.currencyId,
      eventRatio: row.eventRatio,
      dailyAmount: row.dailyAmount,
      volumeDriver: row.volumeDriver,
      volumeDriverId: row.volumeDriverId,
      updateDtm: new Date(row.updateDtm.value),
      linkedCategoryType: row.linkedCategoryType,
      includeSummarySwt: row.includeSummarySwt,
    }))
    
    // Batch insert with proper error handling
    const batchSize = 1000
    for (let i = 0; i < volumeForecastData.length; i += batchSize) {
      const batch = volumeForecastData.slice(i, i + batchSize)
      await prisma.vVolumeForecast.createMany({
        data: batch,
        skipDuplicates: true
      })
    }
    
    // Similar batch processing for other data types...
    // This is a simplified version - full implementation would handle all data types
  }

  getProjectId(): string {
    return this.projectId
  }

  getDataset(): string {
    return this.dataset
  }

  async executeQuery(query: string, params: any[] = []): Promise<any[]> {
    if (!this.client) {
      throw new Error('BigQuery client not initialized')
    }

    try {
      const [rows] = await this.client.query({
        query,
        params: params.length > 0 ? params : undefined
      })
      return rows
    } catch (error) {
      console.error('BigQuery query execution failed:', error)
      throw error
    }
  }

  async getTableInfo(projectId: string, dataset: string, tableName: string): Promise<any> {
    if (!this.client) {
      throw new Error('BigQuery client not initialized')
    }

    try {
      // Get table metadata
      const [metadata] = await this.client.dataset(dataset).table(tableName).getMetadata()
      
      // Get table schema
      const [schema] = await this.client.dataset(dataset).table(tableName).getSchema()
      
      // Get row count (approximate)
      const [job] = await this.client.createQueryJob({
        query: `SELECT COUNT(*) as row_count FROM \`${projectId}.${dataset}.${tableName}\``
      })
      const [rows] = await job.getQueryResults()
      const rowCount = rows[0]?.row_count || 0

      return {
        tableName,
        dataset,
        projectId,
        rowCount,
        schema: schema.fields,
        metadata: {
          creationTime: metadata.creationTime,
          lastModifiedTime: metadata.lastModifiedTime,
          numBytes: metadata.numBytes,
          numRows: metadata.numRows,
          type: metadata.type
        }
      }
    } catch (error) {
      console.error('Failed to get table info:', error)
      throw error
    }
  }
} 